{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def ffd(a: np.ndarray, c: int):\n",
    "    # First-fit-decreasing bin packing\n",
    "    # https://en.wikipedia.org/wiki/First-fit-decreasing_bin_packing\n",
    "\n",
    "    a = np.sort(a)[::-1]\n",
    "    bins = []\n",
    "    for size in a:\n",
    "        add_new = True\n",
    "        for idx in range(len(bins)):\n",
    "            if bins[idx] >= size:\n",
    "                bins[idx] -= size\n",
    "                add_new = False\n",
    "                break\n",
    "\n",
    "        if add_new:\n",
    "            bins.append(c - size)\n",
    "\n",
    "    return len(bins)\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def ffd_with_result(a: np.ndarray, c: int, start_index: int):\n",
    "    # First-fit-decreasing bin packing (with result return)\n",
    "\n",
    "    indices = np.argsort(a)[::-1]\n",
    "    a = a[indices]\n",
    "\n",
    "    bins = []\n",
    "    bins_result = []\n",
    "    for a_id, size in enumerate(a):\n",
    "        add_new = True\n",
    "        for idx in range(len(bins)):\n",
    "            if bins[idx] >= size:\n",
    "                bins[idx] -= size\n",
    "                bins_result[idx].append(indices[a_id] + start_index)\n",
    "                add_new = False\n",
    "                break\n",
    "\n",
    "        if add_new:\n",
    "            bins.append(c - size)\n",
    "            bins_result.append([indices[a_id] + start_index])\n",
    "\n",
    "    return bins_result\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def allocate(lengths: np.ndarray, lengths_cumsum: np.ndarray, rank: int, c: int, n: int):\n",
    "    # Dynamic batch allocator, similar to Multifit\n",
    "    # https://en.wikipedia.org/wiki/Multifit_algorithm\n",
    "    # ~96.4% efficiency on OpenChat training set (2048 ctx len)\n",
    "\n",
    "    s = 0\n",
    "    start_index = 0\n",
    "    result = []\n",
    "\n",
    "    while True:\n",
    "        # binary search [l, r)\n",
    "        l = 1\n",
    "        r = 1 + np.searchsorted(lengths_cumsum[start_index:], s + c * n, \"right\")\n",
    "\n",
    "        while r - l > 1:\n",
    "            m = (l + r) // 2\n",
    "            if ffd(lengths[start_index: start_index + m], c) <= n:\n",
    "                l = m\n",
    "            else:\n",
    "                r = m\n",
    "\n",
    "        # use length l\n",
    "        batch = ffd_with_result(lengths[start_index: start_index + l], c, start_index)\n",
    "        \n",
    "        start_index += l\n",
    "        s = lengths_cumsum[start_index - 1]\n",
    "\n",
    "        # add ffd\n",
    "        if len(batch) < n:\n",
    "            break\n",
    "\n",
    "        result.append(batch[rank])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class FFDDistributedBatchSampler(Sampler):\n",
    "    \"\"\"Unpadded length sampling using FFD (First-fit-decreasing bin packing).\n",
    "       Approximate (at most ~1.22x) the optimal solution of the identical-machines scheduling problem, which is NP-hard.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_max_length: int,\n",
    "        lengths: List[int],\n",
    "        num_replicas: Optional[int] = None,\n",
    "        rank: Optional[int] = None,\n",
    "        seed: int = 0,\n",
    "    ):\n",
    "        # Get rank\n",
    "        if num_replicas is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            num_replicas = dist.get_world_size()\n",
    "        if rank is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            rank = dist.get_rank()\n",
    "\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.seed = seed\n",
    "\n",
    "        self.batch_max_length = batch_max_length\n",
    "        self.lengths = lengths\n",
    "        assert isinstance(self.lengths, np.ndarray)\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    def set_epoch(self, epoch: int):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def generate_batches(self):\n",
    "        indices = np.random.default_rng(seed=self.seed + self.epoch).permutation(len(self.lengths))\n",
    "\n",
    "        lengths = self.lengths[indices]\n",
    "        lengths_cumsum = np.cumsum(lengths)\n",
    "\n",
    "        batches = allocate(lengths=lengths,\n",
    "                           lengths_cumsum=lengths_cumsum,\n",
    "                           rank=self.rank,\n",
    "                           c=self.batch_max_length,\n",
    "                           n=self.num_replicas)\n",
    "        \n",
    "        batches = [indices[batch] for batch in batches]\n",
    "        \n",
    "        return batches\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = self.generate_batches()\n",
    "        return iter(batches)\n",
    "\n",
    "    def num_batches(self):\n",
    "        batches = self.generate_batches()\n",
    "        return len(batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4]]\n"
     ]
    }
   ],
   "source": [
    "lengths = np.array([1, 5, 7, 8, 3, 2])\n",
    "lengths_cumsum = np.cumsum(lengths)\n",
    "\n",
    "print(allocate(lengths, lengths_cumsum, 2, 8, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Efficiency: 0.9645493451286765\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"../../dataset_processed/openchat.train.json\"\n",
    "C = 16 * 2048\n",
    "N = 8\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset\n",
    "with open(DATASET, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Check allocator efficiency\n",
    "lengths = np.array([len(tokens) for tokens, masks in dataset])\n",
    "\n",
    "# test sampler correctness & efficiency\n",
    "tot_len = 0\n",
    "tot_batches = 0\n",
    "\n",
    "samplers = [FFDDistributedBatchSampler(C, lengths, N, rank) for rank in range(N)]\n",
    "for epoch in range(EPOCHS):\n",
    "    batches = []\n",
    "\n",
    "    for sampler in samplers:\n",
    "        sampler.set_epoch(epoch)\n",
    "        for batch in sampler:\n",
    "            batches.extend(batch)\n",
    "\n",
    "            # Check constraints\n",
    "            overall_len = sum([lengths[x] for x in batch])\n",
    "            assert overall_len <= C\n",
    "\n",
    "            tot_len += overall_len\n",
    "            tot_batches += 1\n",
    "\n",
    "    # Check overall unique\n",
    "    batches.sort()\n",
    "    assert batches == list(set(batches))  # Unique\n",
    "\n",
    "# Check efficiency\n",
    "print(f\"Overall Efficiency: {tot_len / (tot_batches * C)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(samplers[0].num_batches())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
